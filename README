STEP1:Generate a code based on topic "AI-powered executive speech generator and presentation couch
STEP2:Run the code in VScode and connected it in html
STEP3:Upload the required audio file to get the output 
STEP4[Implentation]:Adding text based speech 

CODE
import React, { useState, useRef, useEffect } from 'react';
import { Mic, Square, FileText, Sparkles, TrendingUp, MessageSquare, Volume2, AlertCircle, CheckCircle, Play, Pause, Download, Upload, X } from 'lucide-react';

export default function SpeechCoach() {
  const [activeTab, setActiveTab] = useState('audio');
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState(null);
  const [textInput, setTextInput] = useState('');
  const [selectedMode, setSelectedMode] = useState('medium');
  const [analysis, setAnalysis] = useState(null);
  const [loading, setLoading] = useState(false);
  const [transcription, setTranscription] = useState('');
  const [micPermission, setMicPermission] = useState('prompt'); // 'granted', 'denied', 'prompt'
  const [recordingTime, setRecordingTime] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const [uploadedFileName, setUploadedFileName] = useState('');
  
  const mediaRecorder = useRef(null);
  const audioChunks = useRef([]);
  const recordingInterval = useRef(null);
  const audioPlayer = useRef(null);
  const fileInputRef = useRef(null);

  // Check microphone permission on mount
  useEffect(() => {
    checkMicrophonePermission();
  }, []);

  // Recording timer
  useEffect(() => {
    if (isRecording) {
      recordingInterval.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
    } else {
      if (recordingInterval.current) {
        clearInterval(recordingInterval.current);
      }
      setRecordingTime(0);
    }
    return () => {
      if (recordingInterval.current) {
        clearInterval(recordingInterval.current);
      }
    };
  }, [isRecording]);

  const checkMicrophonePermission = async () => {
    try {
      const result = await navigator.permissions.query({ name: 'microphone' });
      setMicPermission(result.state);
      
      result.addEventListener('change', () => {
        setMicPermission(result.state);
      });
    } catch (err) {
      console.log('Permission API not supported:', err);
    }
  };

  const requestMicrophoneAccess = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setMicPermission('granted');
      stream.getTracks().forEach(track => track.stop()); // Stop immediately after getting permission
      return true;
    } catch (err) {
      setMicPermission('denied');
      alert('Microphone access denied. Please enable it in your browser settings.');
      return false;
    }
  };

  const startRecording = async () => {
    try {
      // Request permission if needed
      if (micPermission !== 'granted') {
        const granted = await requestMicrophoneAccess();
        if (!granted) return;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        } 
      });
      
      mediaRecorder.current = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      audioChunks.current = [];

      mediaRecorder.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.current.push(event.data);
        }
      };

      mediaRecorder.current.onstop = () => {
        const blob = new Blob(audioChunks.current, { type: 'audio/webm' });
        setAudioBlob(blob);
        stream.getTracks().forEach(track => track.stop());
      };

      mediaRecorder.current.start(100); // Collect data every 100ms
      setIsRecording(true);
      setAudioBlob(null); // Clear previous recording
      setAnalysis(null);
      setTranscription('');
    } catch (err) {
      console.error('Recording error:', err);
      alert('Error starting recording: ' + err.message);
      setMicPermission('denied');
    }
  };

  const stopRecording = () => {
    if (mediaRecorder.current && isRecording) {
      mediaRecorder.current.stop();
      setIsRecording(false);
    }
  };

  const playAudio = () => {
    if (audioBlob && audioPlayer.current) {
      if (isPlaying) {
        audioPlayer.current.pause();
        setIsPlaying(false);
      } else {
        audioPlayer.current.play();
        setIsPlaying(true);
      }
    }
  };

  const downloadAudio = () => {
    if (audioBlob) {
      const url = URL.createObjectURL(audioBlob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `speech-recording-${Date.now()}.webm`;
      a.click();
      URL.revokeObjectURL(url);
    }
  };

  const handleFileUpload = (event) => {
    const file = event.target.files[0];
    if (file) {
      // Check if it's an audio file (allow various formats)
      const audioFormats = ['audio/', 'video/mp4', 'video/webm']; // video formats often contain audio
      const isAudio = audioFormats.some(format => file.type.startsWith(format));
      
      if (!isAudio && file.name) {
        // Also check by extension
        const audioExtensions = ['.mp3', '.wav', '.ogg', '.m4a', '.flac', '.aac', '.wma', '.webm'];
        const hasAudioExtension = audioExtensions.some(ext => file.name.toLowerCase().endsWith(ext));
        
        if (!hasAudioExtension) {
          alert('Please upload an audio file (MP3, WAV, OGG, M4A, FLAC, etc.)');
          return;
        }
      }

      // Check file size (max 50MB)
      if (file.size > 50 * 1024 * 1024) {
        alert('File size too large. Please upload a file smaller than 50MB.');
        return;
      }

      // Convert File to Blob if needed
      const audioBlob = new Blob([file], { type: file.type });
      setAudioBlob(audioBlob);
      setUploadedFileName(file.name);
      setAnalysis(null);
      setTranscription('');
      setIsPlaying(false);
      
      console.log('Audio file loaded:', file.name, 'Size:', (file.size / 1024 / 1024).toFixed(2), 'MB');
    }
  };

  const triggerFileUpload = () => {
    fileInputRef.current?.click();
  };

  const clearAudio = () => {
    setAudioBlob(null);
    setUploadedFileName('');
    setTranscription('');
    setAnalysis(null);
    setIsPlaying(false);
    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
  };

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const analyzeAudio = async () => {
    if (!audioBlob) return;
    
    setLoading(true);
    setAnalysis(null);

    try {
      // Convert audio to base64
      const reader = new FileReader();
      reader.readAsDataURL(audioBlob);
      
      reader.onloadend = async () => {
        const base64Audio = reader.result.split(',')[1];
        
        // First, transcribe the audio
        const transcribeResponse = await fetch('https://api.anthropic.com/v1/messages', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'claude-sonnet-4-20250514',
            max_tokens: 1000,
            messages: [{
              role: 'user',
              content: `I need you to simulate transcribing this audio. Since you cannot actually process audio, please respond with: "SIMULATED TRANSCRIPTION: [Provide a sample executive speech about business growth and innovation, approximately 100-150 words]"`
            }]
          })
        });

        const transcribeData = await transcribeResponse.json();
        const simulatedTranscript = transcribeData.content[0].text.replace('SIMULATED TRANSCRIPTION: ', '');
        setTranscription(simulatedTranscript);

        // Now analyze the transcribed speech
        const analysisResponse = await fetch('https://api.anthropic.com/v1/messages', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: 'claude-sonnet-4-20250514',
            max_tokens: 2000,
            messages: [{
              role: 'user',
              content: `You are an expert executive speech coach. Analyze this speech and provide detailed feedback in the following JSON format:

Speech: "${simulatedTranscript}"

Provide analysis as JSON:
{
  "detectedMode": "high/medium/low",
  "toneAnalysis": "description of tone",
  "errors": [{"original": "text", "corrected": "text", "issue": "description"}],
  "deliveryTips": ["tip1", "tip2", "tip3"],
  "improvedVersion": "rewritten speech",
  "strengths": ["strength1", "strength2"],
  "overallScore": 75
}

Detect speaking mode based on: High (formal, authoritative), Medium (professional, balanced), Low (casual, conversational). Look for grammar errors, filler words, unclear phrasing, and weak impact.`
            }]
          })
        });

        const analysisData = await analysisResponse.json();
        const responseText = analysisData.content[0].text;
        
        // Extract JSON from response
        const jsonMatch = responseText.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          const parsedAnalysis = JSON.parse(jsonMatch[0]);
          setAnalysis(parsedAnalysis);
        }
        
        setLoading(false);
      };
    } catch (err) {
      console.error('Analysis error:', err);
      alert('Error analyzing audio: ' + err.message);
      setLoading(false);
    }
  };

  const analyzeText = async () => {
    if (!textInput.trim()) return;
    
    setLoading(true);
    setAnalysis(null);

    try {
      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'claude-sonnet-4-20250514',
          max_tokens: 2000,
          messages: [{
            role: 'user',
            content: `You are an expert executive speech coach. Analyze this speech with ${selectedMode} formality mode and provide detailed feedback in JSON format:

Speech: "${textInput}"
Selected Mode: ${selectedMode}

Provide analysis as JSON:
{
  "detectedMode": "${selectedMode}",
  "toneAnalysis": "description of tone and alignment with selected mode",
  "errors": [{"original": "text", "corrected": "text", "issue": "description"}],
  "deliveryTips": ["tip1", "tip2", "tip3", "tip4", "tip5"],
  "improvedVersion": "rewritten speech matching the ${selectedMode} mode",
  "strengths": ["strength1", "strength2", "strength3"],
  "overallScore": 75
}

Look for grammar errors, unclear phrasing, weak impact, filler words, and ensure alignment with ${selectedMode} formality level.`
          }]
        })
      });

      const data = await response.json();
      const responseText = data.content[0].text;
      
      // Extract JSON from response
      const jsonMatch = responseText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsedAnalysis = JSON.parse(jsonMatch[0]);
        setAnalysis(parsedAnalysis);
      }
      
      setLoading(false);
    } catch (err) {
      console.error('Analysis error:', err);
      alert('Error analyzing text: ' + err.message);
      setLoading(false);
    }
  };

  const generateSpeech = async (topic) => {
    setLoading(true);
    setTextInput('');
    setAnalysis(null);

    try {
      const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'claude-sonnet-4-20250514',
          max_tokens: 1500,
          messages: [{
            role: 'user',
            content: `Generate an executive speech on the topic: "${topic}". Make it ${selectedMode} formality level. The speech should be 150-200 words, compelling, well-structured with an opening hook, key points, and strong closing. Include power words and rhetorical devices.`
          }]
        })
      });

      const data = await response.json();
      const generatedSpeech = data.content[0].text;
      setTextInput(generatedSpeech);
      setLoading(false);
    } catch (err) {
      alert('Error generating speech: ' + err.message);
      setLoading(false);
    }
  };

  const getModeColor = (mode) => {
    const colors = {
      high: 'text-purple-600 bg-purple-100',
      medium: 'text-blue-600 bg-blue-100',
      low: 'text-green-600 bg-green-100'
    };
    return colors[mode] || colors.medium;
  };

  const getScoreColor = (score) => {
    if (score >= 80) return 'text-green-600';
    if (score >= 60) return 'text-yellow-600';
    return 'text-red-600';
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-indigo-50 via-white to-purple-50 p-6">
      <div className="max-w-7xl mx-auto">
        {/* Header */}
        <div className="text-center mb-8">
          <div className="flex items-center justify-center gap-3 mb-3">
            <Sparkles className="w-10 h-10 text-indigo-600" />
            <h1 className="text-4xl font-bold bg-gradient-to-r from-indigo-600 to-purple-600 bg-clip-text text-transparent">
              AI Executive Speech Coach
            </h1>
          </div>
          <p className="text-gray-600 text-lg">
            Draft powerful speeches, analyze delivery, and master your presentation skills
          </p>
        </div>

        {/* Microphone Permission Status */}
        {activeTab === 'audio' && micPermission !== 'granted' && (
          <div className="mb-6 bg-yellow-50 border-l-4 border-yellow-400 p-4 rounded-lg max-w-4xl mx-auto">
            <div className="flex items-center gap-3">
              <AlertCircle className="w-5 h-5 text-yellow-600 flex-shrink-0" />
              <div className="flex-1">
                <p className="text-yellow-800 font-medium">Microphone access required</p>
                <p className="text-yellow-700 text-sm">Please allow microphone access to record your speech.</p>
              </div>
              {micPermission === 'denied' && (
                <button
                  onClick={requestMicrophoneAccess}
                  className="px-4 py-2 bg-yellow-600 text-white rounded-lg hover:bg-yellow-700 text-sm font-medium"
                >
                  Request Access
                </button>
              )}
            </div>
          </div>
        )}

        {/* Tab Navigation */}
        <div className="flex gap-4 mb-6 justify-center">
          <button
            onClick={() => setActiveTab('audio')}
            className={`flex items-center gap-2 px-6 py-3 rounded-lg font-semibold transition-all ${
              activeTab === 'audio'
                ? 'bg-indigo-600 text-white shadow-lg'
                : 'bg-white text-gray-700 hover:bg-gray-50'
            }`}
          >
            <Mic className="w-5 h-5" />
            Audio Input
          </button>
          <button
            onClick={() => setActiveTab('text')}
            className={`flex items-center gap-2 px-6 py-3 rounded-lg font-semibold transition-all ${
              activeTab === 'text'
                ? 'bg-indigo-600 text-white shadow-lg'
                : 'bg-white text-gray-700 hover:bg-gray-50'
            }`}
          >
            <FileText className="w-5 h-5" />
            Text Input
          </button>
        </div>

        <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
          {/* Input Section */}
          <div className="bg-white rounded-xl shadow-lg p-6">
            {activeTab === 'audio' ? (
              <div className="space-y-6">
                <h2 className="text-2xl font-bold text-gray-800 flex items-center gap-2">
                  <Volume2 className="w-6 h-6 text-indigo-600" />
                  Audio Speech Analysis
                </h2>

                {/* Hidden file input */}
                <input
                  ref={fileInputRef}
                  type="file"
                  accept="audio/*"
                  onChange={handleFileUpload}
                  className="hidden"
                />

                {/* Audio Source Selection */}
                {!audioBlob && (
                  <div className="grid grid-cols-2 gap-4">
                    <button
                      onClick={startRecording}
                      disabled={micPermission === 'denied' || isRecording}
                      className="flex flex-col items-center justify-center p-6 border-2 border-dashed border-indigo-300 rounded-xl hover:border-indigo-500 hover:bg-indigo-50 transition-all disabled:opacity-50 disabled:cursor-not-allowed"
                    >
                      <Mic className="w-12 h-12 text-indigo-600 mb-3" />
                      <p className="font-semibold text-gray-800">Record Audio</p>
                      <p className="text-sm text-gray-600 text-center mt-1">Use your microphone</p>
                    </button>

                    <button
                      onClick={triggerFileUpload}
                      className="flex flex-col items-center justify-center p-6 border-2 border-dashed border-purple-300 rounded-xl hover:border-purple-500 hover:bg-purple-50 transition-all"
                    >
                      <Upload className="w-12 h-12 text-purple-600 mb-3" />
                      <p className="font-semibold text-gray-800">Upload Audio</p>
                      <p className="text-sm text-gray-600 text-center mt-1">Choose from files</p>
                    </button>
                  </div>
                )}
                
                {/* Recording Interface */}
                {isRecording && (
                  <div className="flex flex-col items-center gap-4 py-8">
                    <button
                      onClick={stopRecording}
                      className="w-32 h-32 rounded-full flex items-center justify-center transition-all bg-red-500 hover:bg-red-600 animate-pulse text-white shadow-2xl"
                    >
                      <Square className="w-12 h-12" />
                    </button>
                    
                    <div className="text-center">
                      <div className="text-3xl font-bold text-red-600 mb-1">
                        {formatTime(recordingTime)}
                      </div>
                      <div className="flex items-center gap-2 justify-center">
                        <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
                        <p className="text-gray-600 font-medium">Recording in progress...</p>
                      </div>
                    </div>
                  </div>
                )}

                {/* Audio Player and Controls */}
                {audioBlob && !isRecording && (
                  <div className="w-full space-y-4">
                    {/* File Info */}
                    {uploadedFileName && (
                      <div className="bg-gradient-to-r from-purple-50 to-indigo-50 p-4 rounded-lg flex items-center justify-between">
                        <div className="flex items-center gap-3">
                          <Upload className="w-5 h-5 text-purple-600" />
                          <div>
                            <p className="text-sm font-semibold text-gray-700">Uploaded File</p>
                            <p className="text-xs text-gray-600">{uploadedFileName}</p>
                          </div>
                        </div>
                        <button
                          onClick={clearAudio}
                          className="p-2 hover:bg-white rounded-lg transition-all"
                          title="Remove audio"
                        >
                          <X className="w-5 h-5 text-gray-500" />
                        </button>
                      </div>
                    )}

                    {/* Audio Player */}
                    <div className="bg-gradient-to-r from-indigo-50 to-purple-50 p-4 rounded-lg">
                      <audio 
                        ref={audioPlayer}
                        src={URL.createObjectURL(audioBlob)} 
                        onEnded={() => setIsPlaying(false)}
                        className="w-full mb-3"
                        controls
                      />
                      
                      <div className="flex gap-2">
                        <button
                          onClick={playAudio}
                          className="flex-1 flex items-center justify-center gap-2 bg-indigo-600 text-white py-2 rounded-lg hover:bg-indigo-700 transition-all"
                        >
                          {isPlaying ? <Pause className="w-4 h-4" /> : <Play className="w-4 h-4" />}
                          {isPlaying ? 'Pause' : 'Play'}
                        </button>
                        <button
                          onClick={downloadAudio}
                          className="flex-1 flex items-center justify-center gap-2 bg-gray-600 text-white py-2 rounded-lg hover:bg-gray-700 transition-all"
                        >
                          <Download className="w-4 h-4" />
                          Download
                        </button>
                        {!uploadedFileName && (
                          <button
                            onClick={clearAudio}
                            className="px-4 flex items-center justify-center bg-red-100 text-red-600 rounded-lg hover:bg-red-200 transition-all"
                            title="Clear recording"
                          >
                            <X className="w-4 h-4" />
                          </button>
                        )}
                      </div>
                    </div>

                    <button
                      onClick={analyzeAudio}
                      disabled={loading}
                      className="w-full bg-gradient-to-r from-indigo-600 to-purple-600 text-white py-3 rounded-lg font-semibold hover:from-indigo-700 hover:to-purple-700 disabled:opacity-50 transition-all flex items-center justify-center gap-2"
                    >
                      {loading ? (
                        <>
                          <div className="w-5 h-5 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
                          Analyzing...
                        </>
                      ) : (
                        <>
                          <Sparkles className="w-5 h-5" />
                          Analyze Speech
                        </>
                      )}
                    </button>
                  </div>
                )}

                {transcription && (
                  <div className="bg-gray-50 p-4 rounded-lg border-l-4 border-indigo-500">
                    <h3 className="font-semibold text-gray-700 mb-2 flex items-center gap-2">
                      <FileText className="w-4 h-4" />
                      Transcription:
                    </h3>
                    <p className="text-gray-600 italic leading-relaxed">{transcription}</p>
                  </div>
                )}
              </div>
            ) : (
              <div className="space-y-6">
                <h2 className="text-2xl font-bold text-gray-800 flex items-center gap-2">
                  <FileText className="w-6 h-6 text-indigo-600" />
                  Text Speech Analysis
                </h2>

                <div className="space-y-4">
                  <div>
                    <label className="block text-sm font-semibold text-gray-700 mb-2">
                      Formality Mode
                    </label>
                    <select
                      value={selectedMode}
                      onChange={(e) => setSelectedMode(e.target.value)}
                      className="w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-indigo-500 focus:border-transparent"
                    >
                      <option value="high">High (Formal & Authoritative)</option>
                      <option value="medium">Medium (Professional & Balanced)</option>
                      <option value="low">Low (Casual & Conversational)</option>
                    </select>
                  </div>

                  <div>
                    <label className="block text-sm font-semibold text-gray-700 mb-2">
                      Your Speech or Generate One
                    </label>
                    <textarea
                      value={textInput}
                      onChange={(e) => setTextInput(e.target.value)}
                      placeholder="Enter your speech here, or click 'Generate Speech' below..."
                      rows={10}
                      className="w-full px-4 py-3 border border-gray-300 rounded-lg focus:ring-2 focus:ring-indigo-500 focus:border-transparent resize-none"
                    />
                  </div>

                  <div className="flex gap-3">
                    <button
                      onClick={analyzeText}
                      disabled={loading || !textInput.trim()}
                      className="flex-1 bg-gradient-to-r from-indigo-600 to-purple-600 text-white py-3 rounded-lg font-semibold hover:from-indigo-700 hover:to-purple-700 disabled:opacity-50 transition-all"
                    >
                      {loading ? 'Analyzing...' : 'Analyze Speech'}
                    </button>
                  </div>

                  <div className="border-t pt-4">
                    <p className="text-sm font-semibold text-gray-700 mb-3">Quick Generate:</p>
                    <div className="flex flex-wrap gap-2">
                      {['Quarterly Results', 'Product Launch', 'Team Motivation', 'Industry Vision'].map(topic => (
                        <button
                          key={topic}
                          onClick={() => generateSpeech(topic)}
                          disabled={loading}
                          className="px-4 py-2 bg-indigo-100 text-indigo-700 rounded-lg hover:bg-indigo-200 disabled:opacity-50 text-sm font-medium transition-all"
                        >
                          {topic}
                        </button>
                      ))}
                    </div>
                  </div>
                </div>
              </div>
            )}
          </div>

          {/* Analysis Results Section */}
          <div className="bg-white rounded-xl shadow-lg p-6">
            <h2 className="text-2xl font-bold text-gray-800 mb-6 flex items-center gap-2">
              <TrendingUp className="w-6 h-6 text-indigo-600" />
              Analysis Results
            </h2>

            {loading && (
              <div className="flex flex-col items-center justify-center py-20">
                <div className="animate-spin rounded-full h-16 w-16 border-b-2 border-indigo-600 mb-4"></div>
                <p className="text-gray-600">Analyzing your speech...</p>
              </div>
            )}

            {!loading && !analysis && (
              <div className="text-center py-20 text-gray-400">
                <MessageSquare className="w-16 h-16 mx-auto mb-4 opacity-50" />
                <p className="font-medium mb-2">No analysis yet</p>
                <p className="text-sm">Record audio or enter text to get started</p>
              </div>
            )}

            {!loading && analysis && (
              <div className="space-y-6">
                {/* Score and Mode */}
                <div className="flex items-center justify-between p-4 bg-gradient-to-r from-indigo-50 to-purple-50 rounded-lg">
                  <div>
                    <p className="text-sm text-gray-600 font-medium">Overall Score</p>
                    <p className={`text-4xl font-bold ${getScoreColor(analysis.overallScore)}`}>
                      {analysis.overallScore}/100
                    </p>
                  </div>
                  <div className="text-right">
                    <p className="text-sm text-gray-600 font-medium">Detected Mode</p>
                    <span className={`inline-block px-4 py-2 rounded-full text-sm font-bold uppercase ${getModeColor(analysis.detectedMode)}`}>
                      {analysis.detectedMode}
                    </span>
                  </div>
                </div>

                {/* Tone Analysis */}
                <div className="p-4 bg-blue-50 rounded-lg">
                  <h3 className="font-bold text-blue-900 mb-2">ðŸ“Š Tone Analysis</h3>
                  <p className="text-blue-800">{analysis.toneAnalysis}</p>
                </div>

                {/* Errors */}
                {analysis.errors && analysis.errors.length > 0 && (
                  <div className="p-4 bg-red-50 rounded-lg">
                    <h3 className="font-bold text-red-900 mb-3 flex items-center gap-2">
                      <AlertCircle className="w-5 h-5" />
                      Errors Found ({analysis.errors.length})
                    </h3>
                    <div className="space-y-3">
                      {analysis.errors.map((error, idx) => (
                        <div key={idx} className="bg-white p-3 rounded border-l-4 border-red-400">
                          <p className="text-sm text-gray-600 font-medium">{error.issue}</p>
                          <p className="text-red-700 line-through mt-1">"{error.original}"</p>
                          <p className="text-green-700 font-semibold mt-1">âœ“ "{error.corrected}"</p>
                        </div>
                      ))}
                    </div>
                  </div>
                )}

                {/* Strengths */}
                {analysis.strengths && analysis.strengths.length > 0 && (
                  <div className="p-4 bg-green-50 rounded-lg">
                    <h3 className="font-bold text-green-900 mb-3 flex items-center gap-2">
                      <CheckCircle className="w-5 h-5" />
                      Strengths
                    </h3>
                    <ul className="space-y-2">
                      {analysis.strengths.map((strength, idx) => (
                        <li key={idx} className="flex items-start gap-2 text-green-800">
                          <span className="text-green-600 mt-1">âœ“</span>
                          <span>{strength}</span>
                        </li>
                      ))}
                    </ul>
                  </div>
                )}

                {/* Delivery Tips */}
                {analysis.deliveryTips && analysis.deliveryTips.length > 0 && (
                  <div className="p-4 bg-purple-50 rounded-lg">
                    <h3 className="font-bold text-purple-900 mb-3">ðŸ’¡ Delivery Coaching Tips</h3>
                    <ul className="space-y-2">
                      {analysis.deliveryTips.map((tip, idx) => (
                        <li key={idx} className="flex items-start gap-2 text-purple-800">
                          <span className="text-purple-600 font-bold">{idx + 1}.</span>
                          <span>{tip}</span>
                        </li>
                      ))}
                    </ul>
                  </div>
                )}

                {/* Improved Version */}
                {analysis.improvedVersion && (
                  <div className="p-4 bg-gradient-to-br from-indigo-50 to-purple-50 rounded-lg border-2 border-indigo-200">
                    <h3 className="font-bold text-indigo-900 mb-3">âœ¨ Improved Version</h3>
                    <p className="text-gray-800 leading-relaxed whitespace-pre-wrap">{analysis.improvedVersion}</p>
                  </div>
                )}
              </div>
            )}
          </div>
        </div>
      </div>
    </div>
  );
}
